(window.webpackJsonp=window.webpackJsonp||[]).push([[15],{460:function(t,e,a){"use strict";a.r(e);var n=a(2),i=Object(n.a)({},(function(){var t=this,e=t._self._c;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("div",{staticClass:"custom-block tip"},[e("p",{staticClass:"title"}),e("p",[e("font",{attrs:{size:"4"}},[t._v("整理论文和代码，持续更新📝📝📝")])],1)]),t._v(" "),e("h1",{attrs:{id:"papers"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#papers"}},[t._v("#")]),t._v(" Papers")]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",{staticStyle:{"text-align":"center"}},[t._v("Title")]),t._v(" "),e("th",{staticStyle:{"text-align":"center"}},[t._v("Links")]),t._v(" "),e("th",{staticStyle:{"text-align":"center"}},[t._v("Description")])])]),t._v(" "),e("tbody",[e("tr",[e("td",{staticStyle:{"text-align":"center"}},[t._v("ConAM: Confidence Attention Module for Convolutional Neural Networks")]),t._v(" "),e("td",{staticStyle:{"text-align":"center"}},[e("a",{attrs:{href:"/pdfs/CAM.pdf"}},[t._v("PDF")]),t._v(" "),e("a",{attrs:{href:"https://github.com/pcjiang1998/ConfidenceAttentionModule",target:"_blank",rel:"noopener noreferrer"}},[t._v("code"),e("OutboundLink")],1)]),t._v(" "),e("td",{staticStyle:{"text-align":"center"}},[t._v("Confidence Attention模块，即插即用的注意力模块")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"center"}},[t._v("Detecting and Grounding Multi-Modal Media Manipulation")]),t._v(" "),e("td",{staticStyle:{"text-align":"center"}},[e("a",{attrs:{href:"/pdfs/HAMMER.pdf"}},[t._v("PDF")]),t._v(" "),e("a",{attrs:{href:"https://github.com/rshaojimmy/MultiModal-DeepFake",target:"_blank",rel:"noopener noreferrer"}},[t._v("code"),e("OutboundLink")],1)]),t._v(" "),e("td",{staticStyle:{"text-align":"center"}},[t._v("HAMMER模型，提供了大型的图片-文本对篡改数据集 "),e("span",{staticClass:"katex"},[e("span",{staticClass:"katex-mathml"},[e("math",[e("semantics",[e("mrow",[e("mi",[t._v("D")]),e("mi",[t._v("E")]),e("msup",[e("mi",[t._v("M")]),e("mn",[t._v("4")])],1)],1),e("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("DEM^4")])],1)],1)],1),e("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[e("span",{staticClass:"strut",staticStyle:{height:"0.8141079999999999em"}}),e("span",{staticClass:"strut bottom",staticStyle:{height:"0.8141079999999999em","vertical-align":"0em"}}),e("span",{staticClass:"base textstyle uncramped"},[e("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.02778em"}},[t._v("D")]),e("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.05764em"}},[t._v("E")]),e("span",{staticClass:"mord"},[e("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.10903em"}},[t._v("M")]),e("span",{staticClass:"vlist"},[e("span",{staticStyle:{top:"-0.363em","margin-right":"0.05em"}},[e("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[e("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),e("span",{staticClass:"reset-textstyle scriptstyle uncramped"},[e("span",{staticClass:"mord mathrm"},[t._v("4")])])]),e("span",{staticClass:"baseline-fix"},[e("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[e("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),t._v("​")])])])])])])])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"center"}},[t._v("多模态混合注意力机制的虚假新闻检测研究")]),t._v(" "),e("td",{staticStyle:{"text-align":"center"}},[e("a",{attrs:{href:"/pdfs/MAM.pdf"}},[t._v("PDF")])]),t._v(" "),e("td",{staticStyle:{"text-align":"center"}},[t._v("混合注意力机制")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"center"}},[t._v("Dual trustworthy mechanism for cross-domain multi-modality classification")]),t._v(" "),e("td",{staticStyle:{"text-align":"center"}},[e("a",{attrs:{href:"/pdfs/DTMC.pdf"}},[t._v("PDF")]),t._v(" "),e("a",{attrs:{href:"https://github.com/ghh1125/data",target:"_blank",rel:"noopener noreferrer"}},[t._v("code"),e("OutboundLink")],1)]),t._v(" "),e("td",{staticStyle:{"text-align":"center"}},[t._v("双重可信机制CAM和CPM，多模态分类问题")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"center"}},[t._v("GAME-ON: Graph Attention Network based Multimodal Fusion for Fake News Detection")]),t._v(" "),e("td",{staticStyle:{"text-align":"center"}},[e("a",{attrs:{href:"/pdfs/GAME-ON.pdf"}},[t._v("PDF")]),t._v(" "),e("a",{attrs:{href:"https://github.com/mudit-dhawan/GAME-ON",target:"_blank",rel:"noopener noreferrer"}},[t._v("code"),e("OutboundLink")],1)]),t._v(" "),e("td",{staticStyle:{"text-align":"center"}},[t._v("图注意力网络，端到端可训练的简单模型")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"center"}},[t._v("基于多模态学习的虚假新闻检测研究")]),t._v(" "),e("td",{staticStyle:{"text-align":"center"}},[e("a",{attrs:{href:"/pdfs/Survey_of_Fake_News_Detection_with_Multi-model_Learning.pdf"}},[t._v("PDF")])]),t._v(" "),e("td",{staticStyle:{"text-align":"center"}},[t._v("综述，单模态、多模态虚假新闻数据集")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"center"}},[t._v("MFAN: Multi-modal Feature-enhanced Attention Networks for Rumor Detection")]),t._v(" "),e("td",{staticStyle:{"text-align":"center"}},[e("a",{attrs:{href:"/pdfs/MFAN.pdf"}},[t._v("PDF")]),t._v(" "),e("a",{attrs:{href:"https://github.com/drivsaf/MFAN",target:"_blank",rel:"noopener noreferrer"}},[t._v("code"),e("OutboundLink")],1)]),t._v(" "),e("td",{staticStyle:{"text-align":"center"}},[t._v("输入：（文本、图片、用户、评论），利用增强的社交图特征学习来构建社交图的边")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"center"}},[t._v("Leveraging Contrastive Learning and Knowledge Distillation for Incomplete Modality Rumor Detection")]),t._v(" "),e("td",{staticStyle:{"text-align":"center"}},[e("a",{attrs:{href:"/pdfs/CLKD-IMRD.pdf"}},[t._v("PDF")]),t._v(" "),e("a",{attrs:{href:"https://github.com/fupinyun/CLKD-IMRD",target:"_blank",rel:"noopener noreferrer"}},[t._v("code"),e("OutboundLink")],1)]),t._v(" "),e("td",{staticStyle:{"text-align":"center"}},[t._v("利用知识蒸馏来处理不完全模模态的虚假新闻检测问题，对比学习")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"center"}},[t._v("CLFFRD: Curriculum Learning and Fine-grained Fusion for Multimodal Rumor Detection")]),t._v(" "),e("td",{staticStyle:{"text-align":"center"}},[e("a",{attrs:{href:"/pdfs/CLFFRD.pdf"}},[t._v("PDF")]),t._v(" "),e("a",{attrs:{href:"https://github.com/jxnuzl/CLFFRD",target:"_blank",rel:"noopener noreferrer"}},[t._v("code"),e("OutboundLink")],1)]),t._v(" "),e("td",{staticStyle:{"text-align":"center"}},[t._v("课程学习 + 基于细粒度的特征融合")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"center"}},[t._v("MixGen: A New Multi-Modal Data Augmentation")]),t._v(" "),e("td",{staticStyle:{"text-align":"center"}},[e("a",{attrs:{href:"/pdfs/MixGen.pdf"}},[t._v("PDF")]),t._v(" "),e("a",{attrs:{href:"https://github.com/amazon-science/mix-generation",target:"_blank",rel:"noopener noreferrer"}},[t._v("code"),e("OutboundLink")],1)]),t._v(" "),e("td",{staticStyle:{"text-align":"center"}},[t._v("多模态数据增强方法，简单且有效")])]),t._v(" "),e("tr",[e("td",{staticStyle:{"text-align":"center"}},[t._v("Adaptive Fusion Techniques for Multimodal Data")]),t._v(" "),e("td",{staticStyle:{"text-align":"center"}},[e("a",{attrs:{href:"/pdfs/AutoFusion+GANFusion.pdf"}},[t._v("PDF")]),t._v(" "),e("a",{attrs:{href:"https://github.com/Demfier/philo",target:"_blank",rel:"noopener noreferrer"}},[t._v("code"),e("OutboundLink")],1)]),t._v(" "),e("td",{staticStyle:{"text-align":"center"}},[t._v("两种多模态特征融合方法：AutoFusion, GANFusion")])])])])])}),[],!1,null,null,null);e.default=i.exports}}]);