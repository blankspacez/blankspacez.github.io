(window.webpackJsonp=window.webpackJsonp||[]).push([[29],{472:function(s,t,a){"use strict";a.r(t);var n=a(2),e=Object(n.a)({},(function(){var s=this,t=s._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("div",{staticClass:"custom-block tip"},[t("p",{staticClass:"title"}),t("p",[t("font",{attrs:{size:"4"}},[s._v("摘要")])],1),s._v(" "),t("p",[s._v("机器学习实训课程笔记 😈 😈 😈")]),s._v(" "),t("p",[s._v("开发工具："),t("code",[s._v("annaconda")]),s._v(" + "),t("code",[s._v("jupyter notebook")])])]),t("blockquote",[t("p",[s._v("Our work：根据TF-IDF算法提取人民日报文章关键词，提取每篇文章中的Top10关键词。")])]),s._v(" "),t("h2",{attrs:{id:"tf-idf算法"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#tf-idf算法"}},[s._v("#")]),s._v(" TF-IDF算法")]),s._v(" "),t("p",[s._v("Ref: "),t("a",{attrs:{href:"https://blog.csdn.net/asialee_bird/article/details/81486700?ops_request_misc=&request_id=&biz_id=102&utm_term=tf-idf&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-1-81486700.142%5Ev65%5Ejs_top,201%5Ev3%5Econtrol,213%5Ev2%5Et3_control1&spm=1018.2226.3001.4187",target:"_blank",rel:"noopener noreferrer"}},[s._v("TF-IDF算法介绍及实现"),t("OutboundLink")],1),s._v(" & "),t("a",{attrs:{href:"http://fe4ml.apachecn.org/#/docs/4.%E7%89%B9%E5%BE%81%E7%BC%A9%E6%94%BE%E7%9A%84%E6%95%88%E6%9E%9C%EF%BC%9A%E4%BB%8E%E8%AF%8D%E8%A2%8B%E5%88%B0_TF-IDF",target:"_blank",rel:"noopener noreferrer"}},[s._v("特征缩放的效果：从词袋到_TF-IDF"),t("OutboundLink")],1)]),s._v(" "),t("p",[s._v("TF-IDF（term frequency - inverse document frequency，词频-逆向文件频率）是一种用于信息检索与文本挖掘的常用加权技术。")]),s._v(" "),t("p",[s._v("TF-IDF的主要思想是：如果某个单词在一篇文章中出现的频率TF高，并且在其他文章中很少出现，则认为该词或者短语具有很好的类别区分能力，适合用来分类。")]),s._v(" "),t("h3",{attrs:{id:"tf-term-frequency-词频"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#tf-term-frequency-词频"}},[s._v("#")]),s._v(" TF(term frequency，词频)")]),s._v(" "),t("p",[s._v("词频（TF）表示词条（关键字）在文本中出现的频率。")]),s._v(" "),t("img",{attrs:{decoding:"async",src:"/images/221118_01.png",width:"50%"}}),s._v(" "),t("h3",{attrs:{id:"idf-inverse-document-frequency-逆向文件频率"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#idf-inverse-document-frequency-逆向文件频率"}},[s._v("#")]),s._v(" IDF(inverse document frequency，逆向文件频率)")]),s._v(" "),t("p",[s._v("逆向文件频率（IDF）的含义：如果包含词条w的文档越少, 则IDF越大，则说明该词条w具有很好的区分能力。")]),s._v(" "),t("img",{attrs:{decoding:"async",src:"/images/221118_02.png",width:"60%"}}),s._v(" "),t("h3",{attrs:{id:"tf-idf"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#tf-idf"}},[s._v("#")]),s._v(" TF-IDF")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("TF-IDF实际上是TF*IDF")])]),s._v(" "),t("li",[t("p",[s._v("某一特定文件内的高词语频率，以及该词语在整个文件集合中的低文件频率，根据TF-IDF算法具有很高的权重，从而说明这样的词语更为“关键”。")])])]),s._v(" "),t("h2",{attrs:{id:"代码实战"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#代码实战"}},[s._v("#")]),s._v(" 代码实战")]),s._v(" "),t("h3",{attrs:{id:"preparation"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#preparation"}},[s._v("#")]),s._v(" Preparation")]),s._v(" "),t("h4",{attrs:{id:"jieba分词"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#jieba分词"}},[s._v("#")]),s._v(" jieba分词")]),s._v(" "),t("p",[s._v("jieba库是一款优秀的"),t("code",[s._v("Python")]),s._v("第三方中文分词库，在NLP方面较为常用。")]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("    pip install jieba\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("三种分词方式：")]),s._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" jieba\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#精确模式")]),s._v("\njieba"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("lcut（text"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" cut_all"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("False")]),s._v("）\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#全模式")]),s._v("\njieba"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("lcut"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("text"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" cut_all"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#搜索引擎模式")]),s._v("\njieba"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("lcut_for_search"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("text"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br")])]),t("img",{attrs:{decoding:"async",src:"/images/221118_03.png",width:"80%"}}),s._v(" "),t("p",[s._v("提取关键词")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("设置停用词："),t("a",{attrs:{href:"https://gitcode.net/mirrors/goto456/stopwords?utm_source=csdn_github_accelerator",target:"_blank",rel:"noopener noreferrer"}},[s._v("常用停用词表下载"),t("OutboundLink")],1)])]),s._v(" "),t("li",[t("p",[s._v("IDF语料库：jieba自带有IDF语料库，但为了精确提取选择自己通过公式计算IDF")])])]),s._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" jieba"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("analyse\n\njieba"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("analyse"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("extract_tags"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("sentence"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" topK"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("20")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" withWeight"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("False")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" allowPOS"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v("'''\nsentence 为待提取的文本\ntopK 为返回几个 TF/IDF 权重最大的关键词，默认值为 20\nwithWeight 为是否一并返回关键词权重值，默认值为 False\n\nallowPOS 仅包括指定词性的词，默认值为空，即不筛选\n'''")]),s._v("\n\njieba"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("analyse"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("TFIDF"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("idf_path"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#新建TFIDF实例，idf_path 为 IDF 频率文件")]),s._v("\njieba"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("analyse"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("set_idf_path"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("file_name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# file_name为自定义语料库的路径")]),s._v("\njieba"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("analyse"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("set_stop_words"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("file_name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# file_name为自定义停用词的路径")]),s._v("\n\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br")])]),t("h4",{attrs:{id:"docx库"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#docx库"}},[s._v("#")]),s._v(" docx库")]),s._v(" "),t("p",[s._v("因为要分析的语料库中所有的文件都是以.docx为后缀的，对docx文件进行读写操作需要我们使用python自带的docx库。")]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("    pip3 install python-docx\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("上述语句可能出现安装失败的情况，解决方法可以采用下面的语句安装：")]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("pip3 install python-docx -i http://pypi.douban.com/simple --trusted-host pypi.douban.com\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("遍历文件夹中的docx文件内容：")]),s._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" os\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" docx\n\nfilelist"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("os"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("os"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("listdir"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("dirName"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" \n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" fileName "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" filelist"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("fileName"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("split"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'.'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"docx"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 判断文件名后缀")]),s._v("\n        docStr "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" docx"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Document"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("dirName"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'/'")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v("fileName"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        parStr"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('""')]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" paragraph "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" docStr"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("paragraphs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            parStr "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+=")]),s._v(" paragraph"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("text\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br")])]),t("h3",{attrs:{id:"来"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#来"}},[s._v("#")]),s._v(" 🐴🐴🐴来")]),s._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" jieba\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" docx\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" jieba"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("analyse\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" os\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" math\n\ndirName"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"D:/深度学习/机器学习实训/TF-IDF作业"')]),s._v("\nfilelist "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" os"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("listdir"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("dirName"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\nidf_dic"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\ndoc_count"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("len")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("filelist"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 构造自定义IDF语料库")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" fileName "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" filelist"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("fileName"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("split"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'.'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"docx"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        docStr "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" docx"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Document"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("dirName"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'/'")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v("fileName"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        text"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('""')]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" paragraph "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" docStr"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("paragraphs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            text "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+=")]),s._v(" paragraph"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("text\n        words "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" jieba"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("lcut"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("text"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" word "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" words"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("word "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("' '")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n                 idf_dic"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("word"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" idf_dic"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("word"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.0")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" k"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("v "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" idf_dic"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("items"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    idf "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'%.10f'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("%")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("math"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("log"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("doc_count "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" v"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 公式计算IDF，小数点后保留10位")]),s._v("\n    idf_dic"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("k"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" idf\n            \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("with")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("open")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'D:/深度学习/机器学习实训/my_idf.txt'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'w'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("encoding"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'utf-8'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" f"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" k "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" idf_dic"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" k "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'\\n'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            f"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("write"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("k "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("' '")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" idf_dic"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("k"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'\\n'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#写入txt文件，注意utf-8，否则jieba不认")]),s._v("\n\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 设置自定义IDF语料库和停用词表")]),s._v("\njieba"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("analyse"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("set_idf_path"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"D:/深度学习/机器学习实训/my_idf.txt"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  \njieba"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("analyse"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("set_stop_words"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"D:/深度学习/机器学习实训/cn_stopwords.txt"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" \n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 提取关键词")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" fileName "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" filelist"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("fileName"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("split"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'.'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"docx"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        docStr "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" docx"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Document"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("dirName"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'/'")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v("fileName"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        parStr"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('""')]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" paragraph "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" docStr"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("paragraphs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            parStr "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+=")]),s._v(" paragraph"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("text\n        keywords"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("jieba"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("analyse"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("extract_tags"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("parStr"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" topK"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" withWeight"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("False")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" allowPOS"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("fileName"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("keywords"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br"),t("span",{staticClass:"line-number"},[s._v("33")]),t("br"),t("span",{staticClass:"line-number"},[s._v("34")]),t("br"),t("span",{staticClass:"line-number"},[s._v("35")]),t("br"),t("span",{staticClass:"line-number"},[s._v("36")]),t("br"),t("span",{staticClass:"line-number"},[s._v("37")]),t("br"),t("span",{staticClass:"line-number"},[s._v("38")]),t("br"),t("span",{staticClass:"line-number"},[s._v("39")]),t("br"),t("span",{staticClass:"line-number"},[s._v("40")]),t("br"),t("span",{staticClass:"line-number"},[s._v("41")]),t("br"),t("span",{staticClass:"line-number"},[s._v("42")]),t("br"),t("span",{staticClass:"line-number"},[s._v("43")]),t("br"),t("span",{staticClass:"line-number"},[s._v("44")]),t("br"),t("span",{staticClass:"line-number"},[s._v("45")]),t("br"),t("span",{staticClass:"line-number"},[s._v("46")]),t("br"),t("span",{staticClass:"line-number"},[s._v("47")]),t("br")])])])}),[],!1,null,null,null);t.default=e.exports}}]);