(window.webpackJsonp=window.webpackJsonp||[]).push([[20],{467:function(s,t,a){"use strict";a.r(t);var n=a(2),e=Object(n.a)({},(function(){var s=this,t=s._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("div",{staticClass:"custom-block tip"},[t("p",{staticClass:"title"}),t("p",[s._v("ref: "),t("a",{attrs:{href:"https://www.pytorchtutorial.com/docs/",target:"_blank",rel:"noopener noreferrer"}},[s._v("PyTorch中文文档"),t("OutboundLink")],1)]),s._v(" "),t("p",[s._v("PyTorch 是是基于以下两个目的而打造的python科学计算框架：")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("无缝替换NumPy，利用GPU的算力来加速神经网络（cuda）")])]),s._v(" "),t("li",[t("p",[s._v("通过自动求导机制，来让神经网络的实现变得更加容易")])])])]),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" torch\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("h2",{attrs:{id:"张量"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#张量"}},[s._v("#")]),s._v(" 张量")]),s._v(" "),t("p",[s._v("tensor")]),s._v(" "),t("h3",{attrs:{id:"初始化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#初始化"}},[s._v("#")]),s._v(" 初始化")]),s._v(" "),t("ul",[t("li",[s._v("直接生成张量")])]),s._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[s._v("data "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\nx_data "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("tensor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("data"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_data"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v("'''\ntensor([[1, 2],\n        [3, 4]])\n'''")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br")])]),t("ul",[t("li",[s._v("通过numpy数组生成")])]),s._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" numpy "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" np\n\nnp_array "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("array"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("data"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nx_np "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("from_numpy"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("np_array"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v("'''\ntensor([[1, 2],\n        [3, 4]])\n'''")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br")])]),t("ul",[t("li",[s._v("通过已有的张量来生成新的张量")])]),s._v(" "),t("p",[s._v("继承已有张量的数据属性（结构、类型），也可以重写新类型")]),s._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[s._v("x_ones "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ones_like"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_data"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 保留 x_data 的属性")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string-interpolation"}},[t("span",{pre:!0,attrs:{class:"token string"}},[s._v('f"Ones Tensor: \\n ')]),t("span",{pre:!0,attrs:{class:"token interpolation"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("x_ones"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")])]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v(' \\n"')])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\nx_rand "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("rand_like"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_data"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" dtype"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("float")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 重写 x_data 的数据类型")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string-interpolation"}},[t("span",{pre:!0,attrs:{class:"token string"}},[s._v('f"Random Tensor: \\n ')]),t("span",{pre:!0,attrs:{class:"token interpolation"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("x_rand"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")])]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v(' \\n"')])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v("'''\nOnes Tensor: \n tensor([[1, 1],\n        [1, 1]]) \n\nRandom Tensor: \n tensor([[0.2622, 0.2768],\n        [0.2162, 0.0212]]) \n'''")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br")])]),t("ul",[t("li",[s._v("通过指定数据维度来生成张量")])]),s._v(" "),t("p",[s._v("shape是元组类型, 用来描述张量的维数, 下面3个函数通过传入shape来指定生成张量的维数。")]),s._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[s._v("shape "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nrand_tensor "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("rand"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("shape"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nones_tensor "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ones"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("shape"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nzeros_tensor "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("zeros"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("shape"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string-interpolation"}},[t("span",{pre:!0,attrs:{class:"token string"}},[s._v('f"Random Tensor: \\n ')]),t("span",{pre:!0,attrs:{class:"token interpolation"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("rand_tensor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")])]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v(' \\n"')])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string-interpolation"}},[t("span",{pre:!0,attrs:{class:"token string"}},[s._v('f"Ones Tensor: \\n ')]),t("span",{pre:!0,attrs:{class:"token interpolation"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("ones_tensor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")])]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v(' \\n"')])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string-interpolation"}},[t("span",{pre:!0,attrs:{class:"token string"}},[s._v('f"Zeros Tensor: \\n ')]),t("span",{pre:!0,attrs:{class:"token interpolation"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("zeros_tensor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")])]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"')])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v("'''\nRandom Tensor: \n tensor([[0.7244, 0.3744, 0.9196],\n        [0.5778, 0.4171, 0.0868]]) \n\nOnes Tensor: \n tensor([[1., 1., 1.],\n        [1., 1., 1.]]) \n\nZeros Tensor: \n tensor([[0., 0., 0.],\n        [0., 0., 0.]])\n'''")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br")])]),t("h3",{attrs:{id:"属性"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#属性"}},[s._v("#")]),s._v(" 属性")]),s._v(" "),t("ul",[t("li",[s._v("维数：shape")]),s._v(" "),t("li",[s._v("数据类型：dtype")]),s._v(" "),t("li",[s._v("所存储的设备(CPU或GPU)：device")])]),s._v(" "),t("h3",{attrs:{id:"运算"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#运算"}},[s._v("#")]),s._v(" 运算")]),s._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 判断当前环境GPU是否可用, 然后将tensor导入GPU内运行")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("cuda"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("is_available"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    tensor "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tensor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("to"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'cuda'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br")])]),t("h3",{attrs:{id:"索引和切片"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#索引和切片"}},[s._v("#")]),s._v(" 索引和切片")]),s._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[s._v("tensor "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ones"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("to"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\ntensor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("            "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 将第1列(从0开始)的数据全部赋值为0")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("tensor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v("'''\ntensor([[1., 0., 1., 1.],\n        [1., 0., 1., 1.],\n        [1., 0., 1., 1.],\n        [1., 0., 1., 1.]], dtype=torch.int32)\n'''")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br")])]),t("h3",{attrs:{id:"拼接"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#拼接"}},[s._v("#")]),s._v(" 拼接")]),s._v(" "),t("p",[s._v("torch.cat 或 torch.stack，dim为拼接方向的维度")]),s._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[s._v("t1 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("cat"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("tensor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" tensor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" tensor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" dim"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 0:行 1：列")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("t1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v("'''\ntensor([[1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1],\n        [1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1],\n        [1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1],\n        [1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1]], dtype=torch.int32)\n'''")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br")])]),t("h3",{attrs:{id:"张量乘积和矩阵乘法"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#张量乘积和矩阵乘法"}},[s._v("#")]),s._v(" 张量乘积和矩阵乘法")]),s._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 逐个相乘，二者等价")]),s._v("\ntensor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("mul"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("tensor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\ntensor "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" tensor\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 矩阵乘法，二者等价")]),s._v("\ntensor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("matmul"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("tensor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("T"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\ntensor @ tensor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("T\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br")])]),t("h3",{attrs:{id:"自动赋值运算"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#自动赋值运算"}},[s._v("#")]),s._v(" 自动赋值运算")]),s._v(" "),t("p",[s._v("自动赋值运算通常在方法后有 _ 作为后缀，例如: x.copy_(y), x.t_()操作会改变 x 的取值。")]),s._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[s._v("tensor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("add_"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v("'''\ntensor([[6, 5, 6, 6],\n        [6, 5, 6, 6],\n        [6, 5, 6, 6],\n        [6, 5, 6, 6]], dtype=torch.int32)\n'''")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br")])]),t("blockquote",[t("p",[s._v("自动赋值运算虽然可以节省内存, 但在求导时会因为丢失了中间过程而导致一些问题, 所以我们并不鼓励使用它。")])]),s._v(" "),t("h2",{attrs:{id:"autograd"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#autograd"}},[s._v("#")]),s._v(" Autograd")]),s._v(" "),t("p",[t("code",[s._v("torch.autograd")]),s._v("是 PyTorch 的自动差分引擎，可为神经网络训练提供支持。")]),s._v(" "),t("h3",{attrs:{id:"ex-一个训练步骤示例"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#ex-一个训练步骤示例"}},[s._v("#")]),s._v(" ex：一个训练步骤示例")]),s._v(" "),t("p",[s._v("从"),t("code",[s._v("torchvision")]),s._v("加载了经过预训练的"),t("code",[s._v("resnet18")]),s._v("模型。 我们创建一个随机数据张量来表示具有 3 个通道的单个图像，高度&宽度为 64，其对应的label初始化为一些随机值。")]),s._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" torchvision\nmodel "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torchvision"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("models"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("resnet18"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("pretrained"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\ndata "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("rand"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("64")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("64")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nlabels "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("rand"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br")])]),t("p",[s._v("正向传播:")]),s._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[s._v("prediction "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" model"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("data"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# forward pass")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("反向传播，"),t("code",[s._v("Autograd")]),s._v(" 会为每个模型参数计算梯度并将其存储在参数的"),t("code",[s._v(".grad")]),s._v("属性中。")]),s._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[s._v("loss "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("prediction "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" labels"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("sum")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nloss"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("backward"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# backward pass")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br")])]),t("p",[s._v("接下来，我们加载一个优化器，在本例中为随机梯度下降，学习率为 0.01，动量为 0.9。 我们在优化器中注册模型的所有参数。")]),s._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[s._v("optimizer "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("optim"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("SGD"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("model"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("parameters"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" lr"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1e-2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" momentum"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.9")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("调用"),t("code",[s._v(".step()")]),s._v("启动梯度下降。 优化器通过"),t("code",[s._v(".grad")]),s._v("中存储的梯度来调整每个参数。")]),s._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[s._v("optimizer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("step"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# gradient descent")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("h3",{attrs:{id:"ex-autograd如何收集梯度"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#ex-autograd如何收集梯度"}},[s._v("#")]),s._v(" ex：Autograd如何收集梯度")]),s._v(" "),t("p",[s._v("首先用"),t("code",[s._v("requires_grad=True")]),s._v("创建两个张量"),t("code",[s._v("a")]),s._v("和"),t("code",[s._v("b")]),s._v("。 这向autograd发出信号，应跟踪对它们的所有操作。")]),s._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[s._v("a "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("tensor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2.")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3.")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" requires_grad"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nb "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("tensor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6.")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4.")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" requires_grad"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br")])]),t("p",[s._v("从a和b创建另一个张量"),t("code",[s._v("Q")]),s._v("。假设"),t("code",[s._v("a")]),s._v("和"),t("code",[s._v("b")]),s._v("是参数，"),t("code",[s._v("Q")]),s._v("是误差，在"),t("code",[s._v("Q")]),s._v("上调用"),t("code",[s._v(".backward()")]),s._v("时，"),t("code",[s._v("Autograd")]),s._v(" 将计算这些梯度并将其存储在各个张量的"),t("code",[s._v(".grad")]),s._v("属性中。")]),s._v(" "),t("p",[s._v("我们需要在"),t("code",[s._v("Q.backward()")]),s._v("中显式传递"),t("code",[s._v("gradient")]),s._v("参数，因为它是向量。 "),t("code",[s._v("gradient")]),s._v("是与"),t("code",[s._v("Q")]),s._v("形状相同的张量，它表示Q相对于本身的梯度，即\n𝟙\n；同样，我们也可以将"),t("code",[s._v("Q")]),s._v("聚合为一个标量，然后隐式地向后调用，例如"),t("code",[s._v("Q.sum().backward()")]),s._v("。")]),s._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[s._v("Q "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("a"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" b"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 3a^3-b^2")]),s._v("\nexternal_grad "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("tensor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nQ"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("backward"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("gradient"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("external_grad"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Q是张量")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 结果都是true")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("9")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("a"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" a"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("grad"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("b "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" b"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("grad"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br")])]),t("h3",{attrs:{id:"计算图"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#计算图"}},[s._v("#")]),s._v(" 计算图")]),s._v(" "),t("p",[t("code",[s._v("Autograd")]),s._v(" 在由函数对象组成的有向无环图（"),t("code",[s._v("DAG")]),s._v("）中记录数据（张量）和所有已执行的操作（以及由此产生的新张量）。 在此"),t("code",[s._v("DAG")]),s._v("中，叶子是输入张量，根是输出张量。 通过从根到叶跟踪此图，可以使用链式规则自动计算梯度。")]),s._v(" "),t("p",[s._v("在正向传播中，"),t("code",[s._v("Autograd")]),s._v(" 同时执行两项操作：")]),s._v(" "),t("ul",[t("li",[s._v("运行请求的操作以计算结果张量")]),s._v(" "),t("li",[s._v("在 DAG 中维护操作的梯度函数")])]),s._v(" "),t("p",[s._v("当在"),t("code",[s._v("DAG")]),s._v("根目录上调用"),t("code",[s._v(".backward()")]),s._v("时，反向传递开始。"),t("code",[s._v("Autograd")]),s._v("执行：")]),s._v(" "),t("p",[s._v("从每个"),t("code",[s._v(".grad_fn")]),s._v("计算梯度，将它们累积在各自的张量的"),t("code",[s._v(".grad")]),s._v("属性中\n使用链式规则一直传播到叶子张量\n"),t("code",[s._v("DAG")]),s._v(" 在 "),t("code",[s._v("PyTorch")]),s._v(" 中是动态的。要注意的重要一点是，图是从头开始重新创建的； 在每个"),t("code",[s._v(".backward()")]),s._v("调用之后，"),t("code",[s._v("Autograd")]),s._v(" 开始填充新图。 可以根据需要在每次迭代中更改形状，大小和操作。")]),s._v(" "),t("h3",{attrs:{id:"从dag中排除"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#从dag中排除"}},[s._v("#")]),s._v(" 从DAG中排除")]),s._v(" "),t("p",[s._v("对于不需要梯度的张量，将"),t("code",[s._v("requires_grad")]),s._v("属性设置为"),t("code",[s._v("False")]),s._v("会将其从梯度计算 "),t("code",[s._v("DAG")]),s._v(" 中排除。但注意，即使只有一个输入张量该属性为"),t("code",[s._v("True")]),s._v("，操作的输出张量也将需要梯度。")]),s._v(" "),t("p",[s._v("在"),t("code",[s._v("NN")]),s._v("中，不计算梯度的参数通常称为冻结参数。 如果事先知道您不需要这些参数的梯度，则“冻结”模型的一部分会带来性能优势。常见用例：调整预训练网络(finetuning)")]),s._v(" "),t("p",[s._v("在微调中，我们冻结了大部分模型，通常仅修改分类器层以对新标签进行预测。 ex：加载一个预训练的 resnet18 模型，并冻结所有参数。")]),s._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" torch "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" optim\n\nmodel "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torchvision"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("models"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("resnet18"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("pretrained"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Freeze all the parameters in the network")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" param "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" model"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("parameters"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    param"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("requires_grad "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("False")]),s._v("\n\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br")])]),t("p",[s._v("假设我们要在具有 10 个标签的新数据集中微调模型。 在"),t("code",[s._v("resnet")]),s._v(" 中，分类器是最后一个线性层"),t("code",[s._v("model.fc")]),s._v("。 我们可以简单地将其替换为充当我们的分类器的新线性层（默认情况下未冻结）。")]),s._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[s._v("model"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fc "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Linear"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("512")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("现在，除了"),t("code",[s._v("model.fc")]),s._v("的参数外，模型中的所有参数都将冻结。 计算梯度的唯一参数是"),t("code",[s._v("model.fc")]),s._v("的权重和偏差。")]),s._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Optimize only the classifier")]),s._v("\noptimizer "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" optim"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("SGD"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("model"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fc"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("parameters"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" lr"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1e-2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" momentum"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.9")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br")])]),t("p",[s._v("尽管我们在优化器中注册了所有参数，但唯一可计算梯度的参数（因此会在梯度下降中进行更新）是分类器的权重和偏差。")]),s._v(" "),t("p",[t("code",[s._v("torch.no_grad()")]),s._v("中的上下文管理器可以使用相同的排除功能。")]),s._v(" "),t("h2",{attrs:{id:"神经网络"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#神经网络"}},[s._v("#")]),s._v(" 神经网络")]),s._v(" "),t("p",[s._v("可以使用"),t("code",[s._v("torch.nn")]),s._v("包构建神经网络。"),t("code",[s._v("nn")]),s._v("依赖于"),t("code",[s._v("autograd")]),s._v("来定义模型并对其进行微分。")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("定义网络时，需要继承"),t("code",[s._v("nn.Module")]),s._v("，并实现它的"),t("code",[s._v("forward")]),s._v("方法，把网络中具有可学习参数的层放在构造函数"),t("code",[s._v("__init__")]),s._v("中。")])]),s._v(" "),t("li",[t("p",[s._v("只要在"),t("code",[s._v("nn.Module")]),s._v("的子类中定义了"),t("code",[s._v("forward")]),s._v("函数，"),t("code",[s._v("backward")]),s._v("函数就会自动被实现(利用"),t("code",[s._v("autograd")]),s._v(")。")])])]),s._v(" "),t("p",[s._v("神经网络的典型训练过程：")]),s._v(" "),t("ul",[t("li",[s._v("定义具有一些可学习参数（或权重）的神经网络")]),s._v(" "),t("li",[s._v("遍历输入数据集")]),s._v(" "),t("li",[s._v("通过网络处理输入")]),s._v(" "),t("li",[s._v("计算损失（输出正确的距离有多远）")]),s._v(" "),t("li",[s._v("将梯度传播回网络参数")]),s._v(" "),t("li",[s._v("通常使用简单的更新规则来更新网络的权重："),t("code",[s._v("weight")]),s._v(" = "),t("code",[s._v("weight")]),s._v(" - "),t("code",[s._v("learning_rate")]),s._v(" * "),t("code",[s._v("gradient")])])]),s._v(" "),t("h3",{attrs:{id:"创建网络"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#创建网络"}},[s._v("#")]),s._v(" 创建网络")]),s._v(" "),t("p",[s._v("ex: 利用MNIST数据集识别手写数字")]),s._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" torch\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("nn "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" nn\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("functional "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" F\n\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Net")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Module"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("__init__")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("super")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("Net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("__init__"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 1 input image channel, 6 output channels, 5x5 square convolution kernel")]),s._v("\n        self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("conv1 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Conv2d"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("conv2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Conv2d"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("16")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# an affine operation: y = Wx + b")]),s._v("\n        self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fc1 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Linear"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("16")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("120")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 5*5 from image dimension")]),s._v("\n        self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fc2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Linear"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("120")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("84")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fc3 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Linear"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("84")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 指定网络的运行过程")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("forward")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Max pooling over a (2, 2) window")]),s._v("\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" F"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("max_pool2d"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("F"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("relu"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("conv1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# If the size is a square, you can specify with a single number")]),s._v("\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" F"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("max_pool2d"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("F"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("relu"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("conv2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("flatten"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# flatten all dimensions except the batch dimension 拉平x")]),s._v("\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" F"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("relu"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fc1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" F"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("relu"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fc2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fc3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" x\n\n\nnet "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v("'''\nNet(\n  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear(in_features=400, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\n  (fc3): Linear(in_features=84, out_features=10, bias=True)\n)\n'''")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br"),t("span",{staticClass:"line-number"},[s._v("33")]),t("br"),t("span",{staticClass:"line-number"},[s._v("34")]),t("br"),t("span",{staticClass:"line-number"},[s._v("35")]),t("br"),t("span",{staticClass:"line-number"},[s._v("36")]),t("br"),t("span",{staticClass:"line-number"},[s._v("37")]),t("br"),t("span",{staticClass:"line-number"},[s._v("38")]),t("br"),t("span",{staticClass:"line-number"},[s._v("39")]),t("br"),t("span",{staticClass:"line-number"},[s._v("40")]),t("br"),t("span",{staticClass:"line-number"},[s._v("41")]),t("br"),t("span",{staticClass:"line-number"},[s._v("42")]),t("br")])]),t("p",[s._v("模型的可学习参数由net.parameters()返回。")]),s._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[s._v("params "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("list")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("parameters"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("len")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("params"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# foward函数包含10个操作")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v("'''\n10\n'''")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br")])]),t("p",[s._v("尝试一个 32*32 随机输入。")]),s._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("input")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("randn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("32")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("32")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nout "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("input")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("out"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v("'''\ntensor([[ 0.0818, -0.0857,  0.0695,  0.1430,  0.0191, -0.1402,  0.0499, -0.0737,\n         -0.0857,  0.1395]], grad_fn=<AddmmBackward0>)\n'''")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br")])]),t("p",[s._v("使用随机梯度将所有参数和反向传播的梯度缓冲区归零：")]),s._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[s._v("net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("zero_grad"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nout"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("backward"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("randn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br")])]),t("blockquote",[t("p",[s._v("注意："),t("code",[s._v("torch.nn")]),s._v("仅支持"),t("code",[s._v("mini-batch")]),s._v("。 整个"),t("code",[s._v("torch.nn")]),s._v("包仅支持作为微型样本而不是单个样本的输入：ex："),t("code",[s._v("nn.Conv2d")]),s._v("将采用"),t("code",[s._v("nSamples")]),s._v(" x "),t("code",[s._v("nChannels")]),s._v(" x "),t("code",[s._v("Height")]),s._v(" x "),t("code",[s._v("Width")]),s._v("的 4D 张量。如果您只有一个样本，只需使用"),t("code",[s._v("input.unsqueeze(0)")]),s._v("添加一个假批量尺寸。")])]),s._v(" "),t("p",[s._v("总结：")]),s._v(" "),t("ul",[t("li",[t("code",[s._v("torch.Tensor")]),s._v(": 一个多维数组，支持诸如"),t("code",[s._v("backward()")]),s._v("的自动微分操作。 同样，保持相对于张量的梯度。")]),s._v(" "),t("li",[t("code",[s._v("nn.Module")]),s._v(": 神经网络模块。 封装参数的便捷方法，并带有将其移动到 "),t("code",[s._v("GPU")]),s._v("，导出，加载等的帮助器。")]),s._v(" "),t("li",[t("code",[s._v("nn.Parameter")]),s._v(": 一种张量，即将其分配为"),t("code",[s._v("Module")]),s._v("的属性时，自动注册为参数。")]),s._v(" "),t("li",[t("code",[s._v("autograd.Function")]),s._v(": 实现自动微分操作的正向和反向定义。 每个"),t("code",[s._v("Tensor")]),s._v("操作都会创建至少一个"),t("code",[s._v("Function")]),s._v("节点，该节点连接到创建"),t("code",[s._v("Tensor")]),s._v("的函数，并且编码其历史记录。")])]),s._v(" "),t("h3",{attrs:{id:"损失函数"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#损失函数"}},[s._v("#")]),s._v(" 损失函数")]),s._v(" "),t("p",[s._v("损失函数采用一对（输出，目标）输入，并计算一个值，该值估计输出与目标之间的距离。")]),s._v(" "),t("p",[t("code",[s._v("nn")]),s._v("包下有几种不同的损失函数，一个简单的损失是："),t("code",[s._v("nn.MSELoss")]),s._v("，它计算输入和目标之间的均方误差，类似地，还有交叉熵损失"),t("code",[s._v("nn.CrossEntropyLoss")]),s._v("，ex：")]),s._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[s._v("output "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("input")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\ntarget "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("randn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# a dummy target, for example")]),s._v("\ntarget "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" target"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("view"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# make it the same shape as output")]),s._v("\ncriterion "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("MSELoss"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\nloss "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" criterion"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("output"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" target"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("loss"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v("'''\ntensor(0.3117, grad_fn=<MseLossBackward0>)\n'''")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br")])]),t("p",[s._v("现在，如果使用.grad_fn属性向后跟随loss，您将看到一个计算图，如下所示：")]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n      -> view -> linear -> relu -> linear -> relu -> linear\n      -> MSELoss\n      -> loss\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br")])]),t("p",[s._v("当我们调用"),t("code",[s._v("loss.backward()")]),s._v("时，整个图将被微分。 并且图中具有"),t("code",[s._v("requires_grad=True")]),s._v("的所有张量将随梯度累积其"),t("code",[s._v(".grad")]),s._v("张量。")]),s._v(" "),t("p",[s._v("为了说明，让我们向后走几步：")]),s._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("loss"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("grad_fn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# MSELoss")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("loss"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("grad_fn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("next_functions"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Linear")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("loss"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("grad_fn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("next_functions"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("next_functions"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# ReLU")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v("'''\n<MseLossBackward0 object at 0x7f71283dd048>\n<AddmmBackward0 object at 0x7f71283dd7f0>\n<AccumulateGrad object at 0x7f71283dd7f0>\n'''")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br")])]),t("h3",{attrs:{id:"反向传播"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#反向传播"}},[s._v("#")]),s._v(" 反向传播")]),s._v(" "),t("p",[s._v("要反向传播误差，我们要做的只是"),t("code",[s._v("loss.backward()")]),s._v("。 不过，需要清除现有的梯度，否则梯度将累积到现有的梯度中。")]),s._v(" "),t("p",[s._v("ex：看一下"),t("code",[s._v("backward")]),s._v("前后"),t("code",[s._v("conv1")]),s._v("的偏差梯度")]),s._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[s._v("net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("zero_grad"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("     "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# zeroes the gradient buffers of all parameters")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'conv1.bias.grad before backward'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("conv1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("bias"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("grad"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\nloss"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("backward"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'conv1.bias.grad after backward'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("conv1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("bias"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("grad"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v("'''\nconv1.bias.grad before backward\nNone\nconv1.bias.grad after backward\ntensor([ 0.0125, -0.0111,  0.0211, -0.0378, -0.0042, -0.0194])\n'''")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br")])]),t("h3",{attrs:{id:"更新权重"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#更新权重"}},[s._v("#")]),s._v(" 更新权重")]),s._v(" "),t("p",[s._v("实践中使用的最简单的更新规则是随机梯度下降（"),t("code",[s._v("SGD")]),s._v("）：")]),s._v(" "),t("p",[t("code",[s._v("weight")]),s._v(" = "),t("code",[s._v("weight")]),s._v(" - "),t("code",[s._v("learning_rate")]),s._v(" * "),t("code",[s._v("gradient")])]),s._v(" "),t("p",[s._v("使用神经网络时，您希望使用各种不同的更新规则，例如 "),t("code",[s._v("SGD")]),s._v("，"),t("code",[s._v("Nesterov-SGD")]),s._v("，"),t("code",[s._v("Adam")]),s._v("，"),t("code",[s._v("RMSProp")]),s._v(" 等。为实现此目的，"),t("code",[s._v("torch.optim")]),s._v("可实现所有这些方法。 使用它非常简单：")]),s._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("optim "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" optim\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# create your optimizer")]),s._v("\noptimizer "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" optim"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("SGD"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("parameters"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" lr"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.01")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# in your training loop:")]),s._v("\noptimizer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("zero_grad"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# zero the gradient buffers")]),s._v("\noutput "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("input")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nloss "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" criterion"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("output"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" target"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nloss"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("backward"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\noptimizer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("step"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Does the update")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br")])]),t("p",[s._v("注意：需要使用"),t("code",[s._v("optimizer.zero_grad()")]),s._v("将梯度缓冲区手动设置为零。 这是因为如反向传播部分中所述累积了梯度。")])])}),[],!1,null,null,null);t.default=e.exports}}]);